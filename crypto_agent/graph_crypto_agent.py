"""
LangGraph orchestration + Langfuse observability.

ä½¿ç”¨ LangGraph å°‡ Crypto AI Agent çš„æµç¨‹ä¸²æˆæœ‰ç‹€æ…‹çš„ Graphã€‚

State: AgentState
Nodes:
    - fetch_and_analyze span
    - analyst_weekly span + generation
    - analyst_daily span + generation
    - analyst_risk span + generation
    - investment_manager span
    - format_message span
"""

from __future__ import annotations

import datetime as dt
import json
import re
from typing import Any, Dict, List, Optional, TypedDict

import pandas as pd

from langgraph.graph import StateGraph, START, END

from config import SYMBOL
from data_binance import get_daily_klines, get_weekly_klines
from indicators import compute_weekly_regime, analyze_daily_volume_price
from llm_client import chat_json
from observability import SpanCtx, GenCtx, safe_preview
from line_formatter import build_prompt_for_llm, format_line_message

# ----------------------------
# Intent Parsing
# ----------------------------
# Possible intents:
# (from user_text)
# ----------------------------
# 1) general_adviceï¼ˆä¸€èˆ¬å»ºè­°ï¼‰
# 2) bottom_fishingï¼ˆæŠ„åº•ï¼‰
# 3) risk_averseï¼ˆæ€•å›æ’¤ / ä¿å®ˆï¼‰
# 4) take_profitï¼ˆæƒ³è³£å‡º / ç²åˆ©äº†çµï¼‰
# 5) heavy_positionï¼ˆé‡å€‰ / åŠ å€‰ï¼‰
# ----------------------------

def _parse_intent(user_text: str) -> str:
    text = user_text.lower()

    if "æŠ„åº•" in text or "åº•éƒ¨" in text:
        return "bottom_fishing"
    if "æ€•å›æ’¤" in text or "æ€•å›è½" in text or "æ€•è·Œ" in text:
        return "risk_averse"
    if "è³£å‡º" in text or "åœåˆ©" in text or "æƒ³è³£" in text:
        return "take_profit"
    if "é‡å€‰" in text or "åŠ å€‰" in text or "å¤š" in text:
        # avoid matching â€œåšå¤šâ€ for general sentiment
        # so only heavy if explicitly é‡å€‰/åŠ å€‰
        return "heavy_position"
    # fallback general
    return "general_advice"

INTENT_WEIGHTS = {
    "general_advice": {"weekly": 1.0, "daily": 1.0, "risk": 1.0},
    "bottom_fishing": {"weekly": 0.5, "daily": 1.5, "risk": 1.0},
    "risk_averse": {"weekly": 0.5, "daily": 1.0, "risk": 1.5},
    "take_profit": {"weekly": 1.0, "daily": 0.8, "risk": 1.4},
    "heavy_position": {"weekly": 1.0, "daily": 1.2, "risk": 0.8},
}

# ----------------------------
# State Schema
# ----------------------------

class AnalystResult(TypedDict, total=False):
    ok: bool
    focus: str
    summary: str
    decision: str
    notes: str
    missing: List[str]


class AgentState(TypedDict, total=False):
    symbol: str
    user_text: str
    ts: str
    intent: str

    # analysis outputs
    weekly_row: Dict[str, float]
    weekly_regime: str
    daily_pattern: Dict[str, Any]
    daily_candles: List[Dict[str, Any]]

    # multi-analyst results
    analyst_weekly: AnalystResult
    analyst_daily: AnalystResult
    analyst_risk: AnalystResult

    # final
    final_decision: Dict[str, Any]
    message: str
    summary: str



# ----------------------------
# Helpers
# ----------------------------

def _serialize_candles(df: pd.DataFrame, n: int) -> List[Dict[str, Any]]:
    df2 = df.sort_values("close_time").tail(n).copy()
    df2["date"] = df2["close_time"].dt.strftime("%Y-%m-%d")
    out: List[Dict[str, Any]] = []
    for _, r in df2.iterrows():
        out.append(
            {
                "date": str(r["date"]),
                "open": float(r["open"]),
                "high": float(r["high"]),
                "low": float(r["low"]),
                "close": float(r["close"]),
                "volume": float(r["volume"]),
            }
        )
    return out


# ----------------------------
# Prompt Schemas
# ----------------------------

BASE_PROMPT_TEMPLATE = """
[ä½¿ç”¨è€…æå•]
{user_text}

[äº¤æ˜“æ¨™çš„]
{symbol}

[é€±ç·šè³‡è¨Š]
- regime: {weekly_regime}
- close: {close}
- sma50: {sma50}
- sma100: {sma100}

[æ—¥ç·šæ¦‚æ³]
- close_dir: {close_dir}
- vol_ratio: {vol_ratio}

[æ—¥ç·š candles (è¿‘ 35 å¤©)]
{daily_candles}

{special_instructions}
""".strip()


ANALYST_TEMPLATES = {
    "weekly": """
ä½ æ˜¯{role}ã€‚
è«‹ä¾é€±ç·šè³‡è¨Šåšåˆ¤æ–·ï¼Œè«‹å›å‚³åš´æ ¼ JSONï¼š
{{
  "ok": true/false,
  "focus": "weekly",
  "decision": "...(buy/hold/sell)...",
  "summary": "...",
  "confidence": "...(high/medium/low)...",
  "key_levels": {{"support":"...", "resistance":"..."}},
  "notes": "...",
  "missing": []
}}
""".strip(),
    "daily": """
ä½ æ˜¯{role}ã€‚
è«‹ä¾æ—¥ç·šé‡åƒ¹èˆ‡ candles åšåˆ¤æ–·ï¼Œåªå›å‚³ JSONï¼š
{{
  "ok": true/false,
  "focus": "daily",
  "decision": "...",
  "summary": "...",
  "confidence": "...(high/medium/low)...",
  "key_levels": {{"support":"...", "resistance":"..."}},
  "notes": "...",
  "missing": []
}}
""".strip(),
    "risk": """
ä½ æ˜¯{role}ã€‚
è«‹çµåˆä½¿ç”¨è€…æå•èˆ‡å¸‚å ´è³‡è¨Šæå‡ºé¢¨éšªæ§ç®¡ + å€‰ä½ planï¼Œåªå›å‚³ JSONï¼š
{{
  "ok": true/false,
  "focus": "risk",
  "decision": "...",
  "summary": "...",
  "confidence": "...(high/medium/low)...",
  "key_levels": {{"support":"...", "resistance":"..."}},
  "notes": "...",
  "missing": []
}}
""".strip(),
}

MANAGER_LLM_TEMPLATE = """\
ä½ ç¾åœ¨æ˜¯ä¸€ä½è³‡æ·±çš„åŠ å¯†è²¨å¹£ç¾è²¨æŠ•è³‡ç¶“ç†ï¼ˆhuman-level in Chineseï¼‰ã€‚  
ä»¥ä¸‹æ˜¯ä¸‰ä½åˆ†æå¸«æ ¹æ“šå¸‚å ´è³‡æ–™çš„çµæ§‹åŒ–åˆ†æï¼ˆåŒ…å« decision / summary / notes ï¼‰ï¼Œå†åŠ ä¸Šç³»çµ±çš„åˆæ­¥æ±ºç­–(preliminary decision)ã€‚

è«‹ä½ æ‰®æ¼”ã€Œç¶“ç†äººã€ï¼š
- çµ±æ•´ä¸‰ä½åˆ†æå¸«çš„åˆ†æçµæœ
- ä¸åªæ˜¯é‡è¿°ï¼Œè€Œæ˜¯æ¸…æ¥šåœ°è§£é‡‹åŸå› 
- çµ¦å‡ºä¸€å€‹ä¸€è‡´çš„æœ€çµ‚ç­–ç•¥ï¼ˆBUY / HOLD / SELLï¼‰
- ä¸¦æå‡ºæœ€é‡è¦çš„ 2â€“3 å€‹æŠ•è³‡äººæ‡‰è©²æ³¨æ„çš„é¢¨éšªæˆ–è¡Œå‹•å»ºè­°
- åœ¨é–‹é ­å¯ä»¥è¬›åˆ°ä½¿ç”¨è€…æ„åœ–æ˜¯ä½•ç¨®ï¼Œèˆ‡çµ¦å»ºè­°é©ä¸é©åˆåšæ„åœ–çš„äº‹æƒ…
- å…§å®¹ä¸­å¯ä»¥å†ç¸½çµå‡ºåˆ†æå¸«æåˆ°çš„é€±ç·šã€æ—¥ç·šé‡åƒ¹çš„è¶¨å‹¢å…§å®¹ï¼Œä¹Ÿå¯ç¸½çµåˆ†æå¸«æåˆ°çš„æŠ€è¡“ä¿¡è™Ÿæˆ–æŒ‡æ¨™ï¼Œæ³¨æ„è¦ä½¿ç”¨ç¹é«”ä¸­æ–‡
- ä½¿ç”¨è€…æ„åœ–æ˜¯ï¼š{intent}ï¼ˆè«‹å…ˆæ ¹æ“šä¸‹æ–¹æ„åœ–è½‰æ›è¡¨è®Šæ›éå¾Œå†åˆ¤æ–·ï¼‰ï¼Œè«‹ç‰¹åˆ¥æ ¹æ“šæ­¤æ„åœ–çµ¦å‡ºåˆ¤æ–·é‡é»ï¼Œæåˆ°çš„æ„åœ–ä¹Ÿè¦è½‰æ›å¾Œå†è¼¸å‡ºåˆ°çµ¦å‡ºçš„å…§å®¹ä¸­

æ„åœ–è½‰æ›è¡¨ï¼š
- general_adviceï¼šä¸€èˆ¬å»ºè­° / ç›®å‰çœ‹æ³•
- bottom_fishingï¼šæƒ³æŠ„åº•
- risk_averseï¼šæ€•å›æ’¤ / æƒ³ä¿å®ˆ
- take_profitï¼šæƒ³è³£å‡º / ç²åˆ©äº†çµ
- heavy_positionï¼šæƒ³é‡å€‰ / æƒ³åŠ å€‰

**æ³¨æ„ï¼š**
ğŸ”¹ ä¸è¦è¼¸å‡º JSON  
ğŸ”¹ ä¸è¦é€æ¢åˆ—åŸå§‹åˆ†æå¸«æ–‡å­— 
ğŸ”¹ ä¸è¦ä½¿ç”¨ key:value çµæ§‹  
ğŸ”¹ æœ€å¾Œçš„çµè«–æ®µè¦æ˜ç¢ºæŒ‡å‡ºç¸½çµèˆ‡ç†ç”±
ğŸ”¹ ä½¿ç”¨è‡ªç„¶ã€å°ˆæ¥­çš„ä¸­æ–‡ï¼Œè‹±æ–‡åè©æˆ–è‹±æ–‡æŒ‡æ¨™è©èªç­‰ç­‰éƒ½è¦ç›¡é‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡  

ä¸‹é¢æ˜¯å¯ç”¨è³‡è¨Šï¼š

====== ä½¿ç”¨è€…æ„åœ– ======
{intent}

====== é€±ç·šè¶¨å‹¢åˆ†æå¸« ======
Decision: {weekly_decision}
Summary: {weekly_summary}
Notes: {weekly_notes}

====== æ—¥ç·šé‡åƒ¹åˆ†æå¸« ======
Decision: {daily_decision}
Summary: {daily_summary}
Notes: {daily_notes}

====== é¢¨éšªæ§ç®¡åˆ†æå¸« ======
Decision: {risk_decision}
Summary: {risk_summary}
Notes: {risk_notes}

====== ç³»çµ±åˆæ­¥æ±ºç­– ======
{prelim_decision}

---

è«‹ä½ æ’°å¯«ä¸€æ®µã€Œå¯ç›´æ¥çµ¦ä½¿ç”¨è€…çœ‹ã€çš„æŠ•è³‡ç¶“ç†ç¸½çµï¼š

â–¶ é¦–å…ˆä¸€å¥è©±çµ¦å‡ºä½ çš„**æœ€çµ‚æ±ºç­–èˆ‡æœ€é‡è¦ç†ç”±**  
â–¶ æ¥è‘—ç”¨ 2â€“3 å¥æè¿°ä¸‰ä½åˆ†æå¸«çš„å…±è­˜æˆ–åˆ†æ­§é‡é»  
â–¶ æœ€å¾Œçµ¦å‡º 2â€“3 å€‹é¢¨éšªæ§åˆ¶æˆ–è¡Œå‹•å»ºè­°ï¼ˆå®¢è§€ä¸­ç«‹ï¼‰
"""


# ----------------------------
# Nodes
# ----------------------------

def fetch_and_analyze(state: AgentState) -> AgentState:
    symbol = state.get("symbol") or SYMBOL
    user_text = state.get("user_text") or ""
    ts = state.get("ts") or dt.datetime.now().isoformat()
    intent = state.get("intent") or _parse_intent(user_text)

    with SpanCtx("fetch_and_analyze", {"symbol": symbol, "user_text": user_text, "intent": intent, "ts": ts}) as span:
        df_daily = get_daily_klines(symbol, limit=220)
        df_weekly = get_weekly_klines(symbol, limit=220)

        regime, dfw = compute_weekly_regime(df_weekly)
        daily_pattern = analyze_daily_volume_price(df_daily)
        daily_candles = _serialize_candles(df_daily, 35)

        out = {
            "symbol": symbol,
            "user_text": user_text,
            "ts": ts,
            "intent": intent,
            "weekly_regime": regime,
            "weekly_row": {
                "close": dfw.iloc[-1]["close"],
                "sma50": dfw.iloc[-1]["sma50"],
                "sma100": dfw.iloc[-1]["sma100"],
            },
            "daily_pattern": daily_pattern,
            "daily_candles": daily_candles,
        }

        span.update(output={"weekly_regime": regime, "daily_pattern": daily_pattern})
        return out


def _run_analyst(prompt: str, name: str) -> AnalystResult:
    """
    Runs one analyst with trace:
    - SpanCtx for the overall analyst
    - GenCtx for the LLM invocation
    """

    result: AnalystResult = {}
    with SpanCtx(name, {"prompt_preview": safe_preview(prompt, 1200)}) as span:
        try:
            # generation span
            with GenCtx(f"{name}.llm", {"prompt_preview": safe_preview(prompt, 2000)}) as gen:
                raw = chat_json(prompt)
                # attach raw to gen span
                gen.update(output={"raw_preview": safe_preview(raw, 1200)})

            # if raw is dict-like or str
            result = raw if isinstance(raw, dict) else {}

            # attach result to span
            span.update(output={"result_preview": safe_preview(raw, 1200)})
        except Exception as e:
            # if error, log to span metadata
            span.update(
                output={"error": f"{type(e).__name__}: {str(e)[:200]}"},
                metadata={"status": "error"},
            )
            result = {"ok": False, "error": str(e)}

    return result



def multi_analyst_node(state: AgentState) -> AgentState:
    symbol = state["symbol"]
    user_text = state["user_text"]
    weekly_regime = state["weekly_regime"]
    weekly_row = state["weekly_row"]
    daily_pattern = state["daily_pattern"]
    daily_candles = state["daily_candles"]

    base_ctx = BASE_PROMPT_TEMPLATE.format(
        user_text=user_text,
        symbol=symbol,
        weekly_regime=weekly_regime,
        close=weekly_row["close"],
        sma50=weekly_row["sma50"],
        sma100=weekly_row["sma100"],
        close_dir=daily_pattern.get("close_dir"),
        vol_ratio=daily_pattern.get("vol_ratio"),
        daily_candles=json.dumps(daily_candles, ensure_ascii=False),
        special_instructions=f"ä½¿ç”¨è€…æ„åœ–: {state.get('intent')}ã€‚è«‹ç‰¹åˆ¥æ ¹æ“šæ­¤æ„åœ–çµ¦å‡ºåˆ¤æ–·é‡é»ã€‚"
    )

    analysts = {}

    analysts["analyst_weekly"] = _run_analyst(
        ANALYST_TEMPLATES["weekly"].format(role="é€±ç·šè¶¨å‹¢åˆ†æå¸«") + "\n\n" + base_ctx,
        "analyst_weekly",
    )

    analysts["analyst_daily"] = _run_analyst(
        ANALYST_TEMPLATES["daily"].format(role="æ—¥ç·šé‡åƒ¹åˆ†æå¸«") + "\n\n" + base_ctx,
        "analyst_daily",
    )

    analysts["analyst_risk"] = _run_analyst(
        ANALYST_TEMPLATES["risk"].format(role="é¢¨éšªæ§ç®¡åˆ†æå¸«") + "\n\n" + base_ctx,
        "analyst_risk",
    )

    state.update(analysts)
    return state


def investment_manager_node(state: AgentState) -> AgentState:
    """
    åˆä½µ rule-based æ±ºç­–èåˆ + LLM æŠ•è³‡ç¶“ç†ç¸½çµçš„ç¯€é»ã€‚
    - å…ˆåš weighted vote åˆä½µä¸‰ä½åˆ†æå¸«
    - å†ç”¨ investment_manager LLM prompt åšæœ€çµ‚ç¸½çµï¼ˆè‡ªç„¶ä¸­æ–‡ï¼‰
    """

    intent = state.get("intent", "general_advice")
    weights = INTENT_WEIGHTS.get(intent, INTENT_WEIGHTS["general_advice"])

    # 1) Rule-based æ±ºç­–èåˆ
    with SpanCtx("investment_manager", {"intent": intent, "weights": weights}) as span:

        # é †åºå›ºå®šè®€ä¸‰å€‹åˆ†æå¸«
        analysts_keys = [
            ("weekly", "analyst_weekly"),
            ("daily", "analyst_daily"),
            ("risk", "analyst_risk"),
        ]

        # collect & vote
        score = {"buy": 0.0, "hold": 0.0, "sell": 0.0}
        valid_results: List[AnalystResult] = []
        for role_name, key in analysts_keys:
            r = state.get(key, {})
            if isinstance(r, dict) and r.get("ok"):
                valid_results.append(r)
                d = r.get("decision")
                if d in score:
                    score[d] += weights.get(role_name, 1.0)

        if not valid_results:
            # å¦‚æœæ‰€æœ‰åˆ†æå¸«éƒ½ failï¼Œfallback
            fallback_summary = "å¸‚å ´è³‡è¨Šä¸è¶³æˆ–æ¨¡å‹è§£æå¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"
            state["final_decision"] = {
                "final_decision": "hold",
                "summary": fallback_summary,
                "risk": ["ç„¡æœ‰æ•ˆåˆ†æå¸«è¼¸å‡º"],
            }
            span.update(output={"final_decision": state["final_decision"]})
            return state

        # æ±ºç­–
        merged_decision = max(score, key=lambda k: score[k])

        # åˆæ­¥å½™æ•´åˆ†æå¸« summary + risk
        merged_summary = "ï¼›".join([r.get("summary", "") for r in valid_results if r.get("summary")])
        merged_risk_list = []
        for r in valid_results:
            notes = r.get("notes")
            if notes:
                merged_risk_list.extend(notes if isinstance(notes, list) else [notes])

        preliminary = {
            "final_decision": merged_decision,
            "summary": merged_summary,
            "risk": merged_risk_list[:3],
        }

        # æ›´æ–° stateï¼Œä¹‹å¾Œç”¨æ–¼ LLM prompt
        state["final_decision"] = preliminary

        # 2) ç”¨ LLM åšæŠ•è³‡ç¶“ç†ç¸½çµï¼ˆè‡ªç„¶ä¸­æ–‡ï¼‰
        prompt = MANAGER_LLM_TEMPLATE.format(
            intent=intent,

            weekly_decision=state["analyst_weekly"].get("decision", ""),
            weekly_summary=state["analyst_weekly"].get("summary", ""),
            weekly_notes=state["analyst_weekly"].get("notes", ""),

            daily_decision=state["analyst_daily"].get("decision", ""),
            daily_summary=state["analyst_daily"].get("summary", ""),
            daily_notes=state["analyst_daily"].get("notes", ""),

            risk_decision=state["analyst_risk"].get("decision", ""),
            risk_summary=state["analyst_risk"].get("summary", ""),
            risk_notes=state["analyst_risk"].get("notes", ""),

            prelim_decision=merged_decision,
        )

        # å‘¼å« LLM summaryï¼Œä¸¦æŠŠå›å‚³ç•¶ä½œ summary_text
        with GenCtx("investment_manager.llm", {"prompt_preview": safe_preview(prompt, 2000)}) as gen:
            raw = chat_json(prompt)
            gen.update(output={"raw_preview": safe_preview(raw, 1200)})

        # LLM æœ‰å›æ–‡å­—å°±è¦†è“‹æ‰ preliminary summary
        if isinstance(raw, str) and raw.strip():
            # å‡è¨­ LLM å›çš„æ˜¯è‡ªç„¶æ–‡å­—
            final_summary_text = raw.strip()
            final_state_dec = dict(preliminary)
            final_state_dec["summary"] = final_summary_text
            state["final_decision"] = final_state_dec
            span.update(output={"final_decision": state["final_decision"]})
        else:
            # fallback ï¼ˆè‹¥ LLM å› dict æˆ– parse ä¸æ˜¯æ–‡å­—, å°±ä¿ç•™ preliminaryï¼‰
            span.update(output={"final_decision_fallback": state["final_decision"]})

    return state


def format_message_node(state: AgentState) -> AgentState:
    # ä½ æƒ³åœ¨ Langfuse çœ‹åˆ°å“ªäº› inputï¼Œå°±æŒ‘é‡è¦çš„æ”¾é€™è£¡
    span_input = {
        "symbol": state.get("symbol"),
        "intent": state.get("intent"),
        "final_decision": state.get("final_decision"),
    }

    with SpanCtx("format_message", span_input) as span:
        final = state["final_decision"]
        msg = format_line_message(state["symbol"], final)

        # è¨˜éŒ„è¼¸å‡ºé è¦½
        span.update(output={"message_preview": safe_preview(msg, 300)})

        # âœ… æŠŠ message æ”¾å› stateï¼ˆä¸è¦åª return {"message": msg}ï¼‰
        state["message"] = msg

    return state


def build_graph():
    builder = StateGraph(AgentState)

    builder.add_node("fetch_and_analyze", fetch_and_analyze)
    builder.add_node("multi_analyst", multi_analyst_node)
    builder.add_node("investment_manager", investment_manager_node)
    builder.add_node("format_message", format_message_node)

    builder.add_edge(START, "fetch_and_analyze")
    builder.add_edge("fetch_and_analyze", "multi_analyst")
    builder.add_edge("multi_analyst", "investment_manager")
    builder.add_edge("investment_manager", "format_message")
    builder.add_edge("format_message", END)

    return builder.compile()


def run_with_graph(symbol: str, user_text: str | None = None) -> str:
    symbol = symbol.upper()
    user_text = user_text or f"{symbol} æŠ•è³‡å»ºè­°"
    ts = dt.datetime.now().isoformat()
    intent = _parse_intent(user_text)

    with SpanCtx(
        "crypto_agent.run",
        {"symbol": symbol, "intent": intent, "ts": ts},
    ) as root:

        graph = build_graph()
        final_state: AgentState = graph.invoke(
            {
                "symbol": symbol,
                "user_text": user_text,
                "intent": intent,
                "ts": ts,
            }
        )
        root.update(output={"final_message": final_state.get("message", "")})

    return final_state["message"]
